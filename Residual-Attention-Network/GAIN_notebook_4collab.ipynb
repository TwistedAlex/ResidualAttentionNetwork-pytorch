{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "29AjQjLKQ950"
   },
   "outputs": [],
   "source": [
    "# Please do not change this cell because some hidden tests might depend on it.\n",
    "import os\n",
    " \n",
    "def shell(commands, warn=True):\n",
    "    \"\"\"Executes the string `commands` as a sequence of shell commands.\n",
    "     \n",
    "       Prints the result to stdout and returns the exit status. \n",
    "       Provides a printed warning on non-zero exit status unless `warn` \n",
    "       flag is unset.\n",
    "    \"\"\"\n",
    "    file = os.popen(commands)\n",
    "    print (file.read().rstrip('\\n'))\n",
    "    exit_status = file.close()\n",
    "    if warn and exit_status != None:\n",
    "        print(f\"Completed with errors. Exit status: {exit_status}\\n\")\n",
    "    return exit_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OEjJuj_wVGCh"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDVF1vt_aXxZ",
    "outputId": "154a5acb-1cfc-4cae-c3f7-a461e7a2dc01"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shell' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_86912\\1064421492.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m shell(\"\"\"\n\u001B[0m\u001B[0;32m      2\u001B[0m  \u001B[0mgit\u001B[0m \u001B[0mclone\u001B[0m \u001B[0mhttps\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m//\u001B[0m\u001B[0mgithub\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcom\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0milyak93\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mGAIN\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mpytorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m  \u001B[0mmv\u001B[0m \u001B[1;33m.\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mGAIN\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mpytorch\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;33m*\u001B[0m \u001B[1;33m.\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m  \u001B[0mrm\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0mr\u001B[0m \u001B[0mGAIN\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mpytorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'shell' is not defined"
     ]
    }
   ],
   "source": [
    "shell(\"\"\"\n",
    " git clone https://github.com/ilyak93/GAIN-pytorch\n",
    " mv ./GAIN-pytorch*/* ./\n",
    " rm -r GAIN-pytorch\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6tRR4H5taXxK"
   },
   "outputs": [],
   "source": [
    " \n",
    " \n",
    "# Otter grader does not handle ! commands well, so we define and use our\n",
    "# own function to execute shell commands.\n",
    " \n",
    " \n",
    " \n",
    "# !pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQVfC9hHsC5j"
   },
   "source": [
    "$$\n",
    "\\renewcommand{\\vect}[1]{\\mathbf{#1}}\n",
    "\\renewcommand{\\cnt}[1]{\\sharp(#1)}\n",
    "\\renewcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\renewcommand{\\softmax}{\\operatorname{softmax}}\n",
    "\\renewcommand{\\Prob}{\\Pr}\n",
    "\\renewcommand{\\given}{\\,|\\,}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4Qovn_p59m_U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download needed files and scripts\n",
    "shell(\"\"\"\n",
    " nvidia-smi\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%run main_toFreq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import join as pjoin\n",
    "all_files = sorted(glob.glob(pjoin(pjoin(\"E:/workplace/GAIN-pytorch-main/VOC-dataset/VOCdevkit/VOC2012\", \"SegmentationClass/pre_encoded\"), '*.png')))\n",
    "all_files = [\n",
    "            os.path.splitext(os.path.split(f)[-1])[0] for f in all_files\n",
    "        ]\n",
    "print(\"2007_000256\" in all_files)\n",
    "all_files_preencode = sorted(glob.glob(pjoin(pjoin(\"E:/workplace/GAIN-pytorch-main/VOC-dataset/VOCdevkit/VOC2012\", \"JPEGImages\"), '*.jpg')))\n",
    "all_files_preencode = [\n",
    "            os.path.splitext(os.path.split(f)[-1])[0] for f in all_files_preencode\n",
    "        ]\n",
    "all_files = [\n",
    "                f for f in all_files if (f in all_files_preencode)\n",
    "            ]\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0fem6lekoun",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kill' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kill 49528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0klXvF8e1pX"
   },
   "source": [
    "Reproducing results of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uXvILihcWC9Z",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lBpgQgbeWZJc",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6ab5c92bee87ac18\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6ab5c92bee87ac18\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6018;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port=6018 --host=localhost --logdir=\"E:\\workplace\\ResidualAttentionNetwork-pytorch\\logs\\50e_single\\logs_2022-10-14_11-26-48\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a491826c2dfe717d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a491826c2dfe717d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port=6012 --host=localhost  --logdir=\"E:\\workplace\\GAIN-pytorch-main\\logs_deepfake\\cvpr_s2p1_rp_exacc_e200_2022-10-04_12-35-37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1d5383e2a3355595\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1d5383e2a3355595\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6017;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port=6017  --host=localhost --logdir=\"E:\\workplace\\GAIN-pytorch-main\\logs_deepfake\\cvpr_s1p05_ex_e120_2022-08-06_23-53-17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-559dcba5356b95da\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-559dcba5356b95da\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6019;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port=6019 --host=localhost --logdir=\"E:\\workplace\\GAIN-pytorch-main\\logs_deepfake\\cvpr_s2p1_debg_e120_2022-08-30_04-33-36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E:\\workplace\\GAIN-pytorch-main\\logs_deepfake\\cvpr_ex_mouth_e120_2022-07-25_04-20-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run main_GAIN_MedT.py --batchsize=20 --total_epochs=50 --nepoch=6000 --nepoch_am=100 --nepoch_ex=1 \\\n",
    "         --masks_to_use=1 --lr=0.0001 --pos_to_write_train=50 --neg_to_write_train=20 \\\n",
    "\t\t --pos_to_write_test=50 --neg_to_write_test=50 --log_name=ex_1_all --cl_weight=1 \\\n",
    "\t\t --am_weight=1 --ex_weight=1 ----am_on_all=1 --grad_magnitude=1 --test_before_train=0 \\\n",
    "\t\t --batch_pos_dist=0.25 --input_dir=C:/MDT_dataset/SB3_ulcers_mined_roi_mult/ \\\n",
    "\t\t --output_dir=./ --checkpoint_name=ex_1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PQjZwK4baph"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "%run main_GAIN_VOC.py --grads_off=0 --npretrain=1 --epoch_size=10 --dataset_path=E:/workplace/GAIN-pytorch-main/VOC-dataset/ --logging_path=E:/workplace/GAIN-pytorch-main/logs/ --logging_name=without_grad --device=cuda:0 --checkpoint_file_path_save=E:/workplace/GAIN-pytorch-main/saveHistory/ --checkpoint_nepoch=1 --nepoch=5 --npretrain=1 --record_itr_train=1 --record_itr_test=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp5KW9JKJBuC"
   },
   "source": [
    "Clean all the files after an update to your repo (if you did one), without affecting your drive (unmounting it temporary) and reclone them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Register forward hook !\n",
      "Register backward hook !\n",
      "Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\muzihuole\\Anaconda3\\envs\\GANNEW\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "E:\\workplace\\GAIN-pytorch-main\\models\\batch_GAIN_VOC.py:142: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = F.softmax(logits_cl).argmax(dim=1)\n",
      "D:\\Users\\muzihuole\\Anaconda3\\envs\\GANNEW\\lib\\site-packages\\torch\\nn\\functional.py:3672: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
      "D:\\Users\\muzihuole\\Anaconda3\\envs\\GANNEW\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aeroplane', '0.0793']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\workplace\\GAIN-pytorch-main\\main_GAIN_VOC_test.py:157: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_scores = nn.Softmax()(logits_cl[0].detach())\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "%run main_GAIN_VOC_test.py --grads_off=0 --file_name=2008_000033 --dataset_path=E:/workplace/GAIN-pytorch-main/VOC-dataset/ --logging_path=E:/workplace/GAIN-pytorch-main/logs/test/ --logging_name=without_sup --device=cuda:0  --checkpoint_file_path_load=E:/workplace/GAIN-pytorch-main/saveHistory/2022-04-24_10-03-36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYPxa25gXp0b",
    "outputId": "4ae63562-807a-496c-bcfa-13ccaba6d01e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.flush_and_unmount()\n",
    "\n",
    "!rm -r ./*\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "shell(\"\"\"\n",
    " git clone https://github.com/ilyak93/GAIN-pytorch/\n",
    " mv ./GAIN-pytorch*/* ./\n",
    " rm -r GAIN-pytorch\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GAIN_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "title": "236299 Project Segment 3: Parsing – The CKY Algorithm"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}